{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faf79f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002,2009,2016,2023,2037,2044,2051,2058,2072,2079,2086,2093,2107,2114,2121,2128,2142,2149,2156,2163,2177,2184,2191,2198,2212,2219,2226,2233,2247,2254,2261,2268,2282,2289,2296,2303,2317,2324,2331,2338,2352,2359,2366,2373,2387,2394,2401,2408,2422,2429,2436,2443,2457,2464,2471,2478,2492,2499,2506,2513,2527,2534,2541,2548,2562,2569,2576,2583,2597,2604,2611,2618,2632,2639,2646,2653,2667,2674,2681,2688,2702,2709,2716,2723,2737,2744,2751,2758,2772,2779,2786,2793,2807,2814,2821,2828,2842,2849,2856,2863,2877,2884,2891,2898,2912,2919,2926,2933,2947,2954,2961,2968,2982,2989,2996,3003,3017,3024,3031,3038,3052,3059,3066,3073,3087,3094,3101,3108,3122,3129,3136,3143,3157,3164,3171,3178,3192,3199\n"
     ]
    }
   ],
   "source": [
    "# Q 1\n",
    "a=[str(num) for num in range(2000,3201) if num % 7 == 0 and num % 5 !=0]\n",
    "print(','.join(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553d209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q 3\n",
    "#ans:I will use feature selection for reduce the column \n",
    "# identify and and only keep the most relevent column\n",
    "# we can also use principle component analysis to reduce the dimensions of the column\n",
    "#Principle component analysis will reduce the number of features while preserving the essential information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c4756e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q 4 \n",
    "# ans:achieving a higher accuracy is positive but we are happy becasue \n",
    "# If the dataset is imbalanced where the number of positive and negative samples is different in this situation higher accuracy \n",
    "#might be misleading\n",
    "#Probabolity: Probability is measure of the event will occure or not\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadf3bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5\n",
    "# ans : this will happen because decision tree may not able to capture the complexity of time series data  \n",
    "# while time series regression model may more capable to handle the complexity of the data\n",
    "# also the time series model need data preprocessing technique like handlinh seasonality,trend etc\n",
    "#these steps enhnce the models ability thats why time series works better than decesion tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4497159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q 6\n",
    "# if our data is suffering from low bias and high variance the its facing the overfitting problem in that data worl well on \n",
    "# training dataset and not on testing dataset\n",
    "# to overcome this problem we can use cross validation technique, this will help in identifying the overfitting and choosing \n",
    "# the model that perform the well on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ea9289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q 7\n",
    "# ans:yes we would remove the highly correleated variables before applying PCA\n",
    "# PCS is use for reducing the dimension of the dataset redicung correlation can lead to the more interpretable results\n",
    "#It also enhance the efficiency of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56bf9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q 8\n",
    "#ans:To check the multicollinearity of the model we can use correlation matrix it gives the idea about which features are \n",
    "#highly correlated with each other \n",
    "# we can still build the good model by reducing the multicollinearity of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe0a865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q 9 \n",
    "# ans : ridge and lasso regression are regularization parameter used to reduce the overfitting the th dataset\n",
    "#choice between ridge and lasso depends upon the charecteristics of the datset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47a24c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 3, 4, 5)\n"
     ]
    }
   ],
   "source": [
    "# Q 13 \n",
    "tuple = (1,2,3,4,5,6,7,8,9,10)\n",
    "index = len(tuple)//2\n",
    "print(tuple[:index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5603079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 102, 104, 106, 108, 110, 112, 114, 116, 118, 120, 122, 124, 126, 128, 130, 132, 134, 136, 138, 140, 142, 144, 146, 148, 150, 152, 154, 156, 158, 160, 162, 164, 166, 168, 170, 172, 174, 176, 178, 180, 182, 184, 186, 188, 190, 192, 194, 196, 198, 200]\n"
     ]
    }
   ],
   "source": [
    "# Q 14\n",
    "even_numbers = list(range(100,201,2))\n",
    "print(even_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9ffc7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
